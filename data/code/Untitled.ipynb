{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "19c137c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageData():\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        self.ch = ''\n",
    "\n",
    "        self.typ = ''\n",
    "\n",
    "        self.no_note = ''\n",
    "        self.no_velocity = ''\n",
    "        self.no_time = ''\n",
    "\n",
    "        self.cc_control = ''\n",
    "        self.cc_value = ''\n",
    "        self.cc_time = ''\n",
    "\n",
    "        self.pw_pitch = ''\n",
    "        self.pw_time = ''\n",
    "\n",
    "        self.program_change = ''\n",
    "\n",
    "        self.meta = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b13ff7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "def preprocess(filename =  'HotelCalifornia.mid'):\n",
    "    data = []\n",
    "    mid = MidiFile(filename)\n",
    "    speed = mid.ticks_per_beat  \n",
    "\n",
    "\n",
    "    for n, track in enumerate(mid.tracks[1:]):\n",
    "        typ = ''\n",
    "\n",
    "        no_note = ''\n",
    "        no_velocity = ''\n",
    "        no_time = ''\n",
    "        lno = 0\n",
    "\n",
    "        cc_control = ''\n",
    "        cc_value = ''\n",
    "        cc_time = ''\n",
    "        lcc = 0\n",
    "\n",
    "        pw_pitch = ''\n",
    "        pw_time = ''\n",
    "        lpw = 0\n",
    "\n",
    "        program_change = ''\n",
    "\n",
    "        for i in track:\n",
    "            if i.type == \"note_on\":\n",
    "                lno += 1\n",
    "                typ += 'no'+' '\n",
    "                no_note += str(i.note)+' '\n",
    "                no_velocity += str(i.velocity)+' '\n",
    "                no_time += str(i.time)+ ' '\n",
    "            elif i.type == \"control_change\":\n",
    "                lcc += 1\n",
    "                typ += 'cc'+' '\n",
    "                cc_control += str(i.control)+' '\n",
    "                cc_value += str(i.value)+' '\n",
    "                cc_time += str(i.time)+' '\n",
    "                #print(i)\n",
    "            elif i.type == \"program_change\":\n",
    "                program_change += str(i.program)+' '+str(i.time)+\"\\n\"\n",
    "                #print('i')\n",
    "            elif i.type == \"pitchwheel\":\n",
    "                lpw += 1\n",
    "                typ += 'pw'+' '\n",
    "                pw_pitch += str(i.pitch)+' '\n",
    "                pw_time += str(i.time)+' '\n",
    "            elif i.is_meta:\n",
    "                pass\n",
    "                #print(i)\n",
    "            else:\n",
    "                print(i, \"at track\", n)\n",
    "\n",
    "        for i in mid.tracks[0]:\n",
    "            if i.type == \"set_tempo\":\n",
    "                tempo = i.tempo\n",
    "            elif i.type == \"time_signature\":\n",
    "                nom = i.numerator\n",
    "                denom = i.denominator\n",
    "            elif i.type == \"key_signature\":\n",
    "                key = i.key\n",
    "\n",
    "        msg = MessageData()\n",
    "        msg.ch = n\n",
    "        msg.typ = typ\n",
    "        msg.no_note = no_note\n",
    "        msg.no_velocity = no_velocity\n",
    "        msg.no_time = no_time\n",
    "        msg.cc_control = cc_control\n",
    "        msg.cc_value = cc_value\n",
    "        msg.cc_time = cc_time\n",
    "        msg.pw_pitch = pw_pitch\n",
    "        msg.pw_time = pw_time\n",
    "        msg.meta = f\"{lno+lcc} {lno} {lcc}\\n\" + program_change\n",
    "\n",
    "        data.append(msg)\n",
    "\n",
    "        \n",
    "    return data, len(mid.tracks)-1, speed, tempo, nom, denom, key\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c708ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "token_type = 'word'\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "\n",
    "def lstm(txt, lenout):\n",
    "    text = txt\n",
    "\n",
    "    seq_length = 100\n",
    "    start_story = '| ' * seq_length\n",
    "    text = start_story + text\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n\\n\\n\\n\\n', start_story)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = re.sub('  +', '. ', text).strip()\n",
    "    text = text.replace('..', '.')\n",
    "    text = re.sub('([!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~])', r' \\1 ', text)\n",
    "    text = re.sub('\\s{2,}', ' ', text)\n",
    "\n",
    "    if token_type == 'word':\n",
    "        tokenizer = Tokenizer(char_level = False, filters = '')\n",
    "    else:\n",
    "        tokenizer = Tokenizer(char_level = True, filters = '', lower = False)\n",
    "    tokenizer.fit_on_texts([text])\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "\n",
    "    def generate_sequences(token_list, step): \n",
    "        X = []\n",
    "        y = []\n",
    "        for i in range(0, len(token_list) - seq_length, step):\n",
    "            X.append(token_list[i: i + seq_length])\n",
    "            y.append(token_list[i + seq_length])\n",
    "        y = to_categorical(y, num_classes = total_words)\n",
    "        num_seq = len(X)\n",
    "        print('Number of sequences:', num_seq, \"\\n\")\n",
    "        return X, y, num_seq\n",
    "\n",
    "    step = 1\n",
    "    seq_length = seq_length\n",
    "\n",
    "    X, y, num_seq = generate_sequences(token_list, step)\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    n_units = 256\n",
    "    embedding_size = 100\n",
    "\n",
    "    text_in = Input(shape = (None,))\n",
    "    embedding = Embedding(total_words, embedding_size)\n",
    "    x = embedding(text_in)\n",
    "    x = LSTM(n_units)(x)\n",
    "    # x = Dropout(0.2)(x)\n",
    "    text_out = Dense(total_words, activation = 'softmax')(x)\n",
    "\n",
    "    model = Model(text_in, text_out)\n",
    "\n",
    "    opti = RMSprop(lr = 0.005)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opti)\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    def sample_with_temp(preds, temperature=1.0):\n",
    "        # helper function to sample an index from a probability array\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "\n",
    "    def generate_text(seed_text, next_words, model, max_sequence_len, temp):\n",
    "        output_text = seed_text\n",
    "        \n",
    "        seed_text = start_story + seed_text\n",
    "        \n",
    "        for _ in range(next_words):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = token_list[-max_sequence_len:]\n",
    "            token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "            \n",
    "            probs = model.predict(token_list, verbose=0)[0]\n",
    "            y_class = sample_with_temp(probs, temperature = temp)\n",
    "            \n",
    "            if y_class == 0:\n",
    "                output_word = ''\n",
    "            else:\n",
    "                output_word = tokenizer.index_word[y_class]\n",
    "                \n",
    "            if output_word == \"|\":\n",
    "                break\n",
    "                \n",
    "            if token_type == 'word':\n",
    "                output_text += output_word + ' '\n",
    "                seed_text += output_word + ' '\n",
    "            else:\n",
    "                output_text += output_word + ' '\n",
    "                seed_text += output_word + ' '             \n",
    "        return output_text\n",
    "\n",
    "    def on_epoch_end(epoch, logs):\n",
    "        seed_text = \"\"\n",
    "        gen_words = 300\n",
    "\n",
    "        #print('Temp 0.2')\n",
    "        generate_text(seed_text, gen_words, model, seq_length, temp = 0.2)\n",
    "        #print('Temp 0.33')\n",
    "        generate_text(seed_text, gen_words, model, seq_length, temp = 0.33)\n",
    "        #print('Temp 0.5')\n",
    "        generate_text(seed_text, gen_words, model, seq_length, temp = 0.5)\n",
    "        #print('Temp 1.0')\n",
    "        generate_text(seed_text, gen_words, model, seq_length, temp = 1)\n",
    "\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "    num_batches = int(len(X) / batch_size)\n",
    "    callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks = [callback], shuffle = True)\n",
    "\n",
    "    def generate_human_led_text(model, max_sequence_len):\n",
    "    \n",
    "        output_text = ''\n",
    "        seed_text = start_story\n",
    "        \n",
    "        from random import randint, random\n",
    "        from tqdm.notebook import tqdm\n",
    "        for _ in tqdm(range(int(lenout))):\n",
    "            token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "            token_list = token_list[-max_sequence_len:]\n",
    "            token_list = np.reshape(token_list, (1, max_sequence_len))\n",
    "            \n",
    "            probs = model.predict(token_list, verbose=0)[0]\n",
    "\n",
    "            top_10_idx = np.flip(np.argsort(probs)[-10:])\n",
    "            top_10_probs = [probs[x] for x in top_10_idx]\n",
    "            top_10_words = tokenizer.sequences_to_texts([[x] for x in top_10_idx])\n",
    "\n",
    "            r = random()\n",
    "            if  1 >= r >= 1 - top_10_probs[0]:\n",
    "                index = 0\n",
    "            elif 1 - top_10_probs[0] > r >= 1 - top_10_probs[0] - top_10_probs[1]:\n",
    "                index = 1\n",
    "            elif 1 - top_10_probs[0] - top_10_probs[1] > r > 1 - top_10_probs[0] - top_10_probs[1] - top_10_probs[2]:\n",
    "                index = 2\n",
    "            else:\n",
    "                index = 3\n",
    "                #print(f\"outlier!: {index}, {r}\")\n",
    "\n",
    "            chosen_word = top_10_words[index]\n",
    "                \n",
    "            \n",
    "            seed_text += chosen_word + ' '\n",
    "            output_text += chosen_word + ' '\n",
    "\n",
    "        #print (output_text)\n",
    "        return output_text\n",
    "\n",
    "    t = generate_human_led_text(model, seq_length)\n",
    "\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64fa3857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mido import MidiFile, MidiTrack, Message, MetaMessage\n",
    "\n",
    "def channel_assemble(data, ch):\n",
    "    trackdata = data[ch]\n",
    "\n",
    "    typ = trackdata.typ.split()\n",
    "    meta = trackdata.meta.split('\\n')\n",
    "    program = meta[1].split() \n",
    "    cc_c = trackdata.cc_control.split()\n",
    "    cc_t = trackdata.cc_time.split()\n",
    "    cc_v = trackdata.cc_value.split()\n",
    "    no_n = trackdata.no_note.split()\n",
    "    no_t = trackdata.no_time.split()\n",
    "    no_v = trackdata.no_velocity.split()\n",
    "    pw_p = trackdata.pw_pitch.split()\n",
    "    pw_t = trackdata.pw_time.split()\n",
    "\n",
    "    noindx, ccindx, pwindx = 0, 0, 0\n",
    "    track = MidiTrack()\n",
    "    if program: \n",
    "        m = Message(\"program_change\", channel = ch, program=int(program[0]), time=int(program[1]))\n",
    "        track.append(m)\n",
    "    for node in typ:\n",
    "        if node == \"no\":\n",
    "            m = Message(\"note_on\", channel = ch, note=int(no_n[noindx]), time=int(no_t[noindx]), velocity=int(no_v[noindx]))\n",
    "            noindx += 1\n",
    "        elif node == \"cc\":\n",
    "            m = Message(\"control_change\", channel = ch, control=int(cc_c[ccindx]), time=int(cc_t[ccindx]), value=int(cc_v[ccindx]))\n",
    "            ccindx += 1\n",
    "        elif node == \"pw\":\n",
    "            m=Message(\"pitchwheel\", channel = ch, pitch=int(pw_p[pwindx]), time=int(pw_t[pwindx]))\n",
    "            pwindx += 1\n",
    "        else:\n",
    "            print(\"Unknown node\", node)\n",
    "        track.append(m)\n",
    "        \n",
    "    return track\n",
    "\n",
    "def postprocessing(data, lentrack, speed=120, tempo = 810810, nom = 4, denom = 4, k = 'C', select = []):\n",
    "\n",
    "    newmid = MidiFile()\n",
    "    newmid.ticks_per_beat=speed\n",
    "    metatrack = MidiTrack()\n",
    "    metatrack.append(MetaMessage(\"set_tempo\", tempo=int(tempo)))\n",
    "    metatrack.append(MetaMessage(\"time_signature\", numerator = int(nom), denominator = int(denom)))\n",
    "    metatrack.append(MetaMessage(\"key_signature\", key=k))\n",
    "    newmid.tracks.append(metatrack)\n",
    "\n",
    "    if select:\n",
    "        for i in range(select):\n",
    "            newmid.tracks.append(channel_assemble(data, i))\n",
    "        newmid.save(\"output.mid\")\n",
    "        return\n",
    "        \n",
    "    for i in range(lentrack):\n",
    "        newmid.tracks.append(channel_assemble(data, i))\n",
    "\n",
    "    newmid.save(\"output.mid\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5308e5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_note_channel(data, ch):\n",
    "    notelen = len(data[ch].no_note)\n",
    "    data[ch].no_note =  lstm(data[ch].no_note, int(notelen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09fd07fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'HotelCalifornia.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3379648",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, n, speed, tempo, nom, denom, key= preprocess(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26c59742",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 9908 \n",
      "\n",
      "Epoch 1/10\n",
      "310/310 [==============================] - 162s 521ms/step - loss: 1.5686\n",
      "Epoch 2/10\n",
      "310/310 [==============================] - 235s 760ms/step - loss: 0.5379\n",
      "Epoch 3/10\n",
      "310/310 [==============================] - 253s 816ms/step - loss: 0.3156\n",
      "Epoch 4/10\n",
      "310/310 [==============================] - 228s 736ms/step - loss: 0.2249\n",
      "Epoch 5/10\n",
      "310/310 [==============================] - 232s 750ms/step - loss: 0.1713\n",
      "Epoch 6/10\n",
      "310/310 [==============================] - 235s 759ms/step - loss: 0.1425\n",
      "Epoch 7/10\n",
      "310/310 [==============================] - 233s 753ms/step - loss: 0.1150\n",
      "Epoch 8/10\n",
      "310/310 [==============================] - 240s 776ms/step - loss: 0.1023\n",
      "Epoch 9/10\n",
      "310/310 [==============================] - 240s 775ms/step - loss: 0.0938\n",
      "Epoch 10/10\n",
      "310/310 [==============================] - 242s 782ms/step - loss: 0.0871\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51623937cc38432e87647ab05372e9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29724 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 1044 \n",
      "\n",
      "Epoch 1/10\n",
      "33/33 [==============================] - 57s 2s/step - loss: 2.1756\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 70s 2s/step - loss: 1.1593\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 72s 2s/step - loss: 0.7107\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 69s 2s/step - loss: 0.4440\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 69s 2s/step - loss: 0.2548\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 69s 2s/step - loss: 0.1917\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 69s 2s/step - loss: 0.1407\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 67s 2s/step - loss: 0.1416\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 69s 2s/step - loss: 0.0880\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 68s 2s/step - loss: 0.0572\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406da90bcd6a4ccea0da4a33c2574c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 1592 \n",
      "\n",
      "Epoch 1/10\n",
      "50/50 [==============================] - 78s 2s/step - loss: 2.0791\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 73s 1s/step - loss: 1.1189\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.6759\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.4252\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.2658\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 68s 1s/step - loss: 0.1971\n",
      "Epoch 7/10\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.1590\n",
      "Epoch 8/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.0960\n",
      "Epoch 9/10\n",
      "50/50 [==============================] - 67s 1s/step - loss: 0.0943\n",
      "Epoch 10/10\n",
      "50/50 [==============================] - 66s 1s/step - loss: 0.0959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed46f42bb73a415d90001726c52144b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4776 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 870 \n",
      "\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 13247s 491s/step - loss: 1.6144\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 59s 2s/step - loss: 0.9917\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.8613\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.7744\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.7236\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 56s 2s/step - loss: 0.6527\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 58s 2s/step - loss: 0.6170\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 59s 2s/step - loss: 0.5784\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 57s 2s/step - loss: 0.5573\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 59s 2s/step - loss: 0.5330\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0656affbbe99405d876d35842489af8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 1630 \n",
      "\n",
      "Epoch 1/10\n",
      "51/51 [==============================] - 68s 1s/step - loss: 2.8952\n",
      "Epoch 2/10\n",
      "51/51 [==============================] - 79s 2s/step - loss: 2.1518\n",
      "Epoch 3/10\n",
      "51/51 [==============================] - 78s 2s/step - loss: 1.7994\n",
      "Epoch 4/10\n",
      "51/51 [==============================] - 76s 2s/step - loss: 1.4925\n",
      "Epoch 5/10\n",
      "51/51 [==============================] - 77s 2s/step - loss: 1.2192\n",
      "Epoch 6/10\n",
      "51/51 [==============================] - 78s 2s/step - loss: 1.0016\n",
      "Epoch 7/10\n",
      "51/51 [==============================] - 85s 2s/step - loss: 0.8275\n",
      "Epoch 8/10\n",
      "51/51 [==============================] - 83s 2s/step - loss: 0.7097\n",
      "Epoch 9/10\n",
      "51/51 [==============================] - 80s 2s/step - loss: 0.5894\n",
      "Epoch 10/10\n",
      "51/51 [==============================] - 84s 2s/step - loss: 0.5011\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc36ed287a3e458db87cb33a93edaa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4890 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 2516 \n",
      "\n",
      "Epoch 1/10\n",
      "79/79 [==============================] - 99s 1s/step - loss: 0.9499\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.6357\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 86s 1s/step - loss: 0.5454\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.4759\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 90s 1s/step - loss: 0.4231\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 88s 1s/step - loss: 0.3486\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 86s 1s/step - loss: 0.2914\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 89s 1s/step - loss: 0.2381\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 87s 1s/step - loss: 0.2228\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 97s 1s/step - loss: 0.1923\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea2a48c19874b8a904d2d9c0591025a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7548 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 0 \n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [42]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(data))):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtrain_note_channel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36mtrain_note_channel\u001b[1;34m(data, ch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_note_channel\u001b[39m(data, ch):\n\u001b[0;32m      2\u001b[0m     notelen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[ch]\u001b[38;5;241m.\u001b[39mno_note)\n\u001b[1;32m----> 3\u001b[0m     data[ch]\u001b[38;5;241m.\u001b[39mno_note \u001b[38;5;241m=\u001b[39m  \u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mch\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_note\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnotelen\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [37]\u001b[0m, in \u001b[0;36mlstm\u001b[1;34m(txt, lenout)\u001b[0m\n\u001b[0;32m    125\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X) \u001b[38;5;241m/\u001b[39m batch_size)\n\u001b[0;32m    126\u001b[0m callback \u001b[38;5;241m=\u001b[39m LambdaCallback(on_epoch_end\u001b[38;5;241m=\u001b[39mon_epoch_end)\n\u001b[1;32m--> 127\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_human_led_text\u001b[39m(model, max_sequence_len):\n\u001b[0;32m    131\u001b[0m     output_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1395\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1393\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnexpected result of `train_function` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1396\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(Empty logs). Please use \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1397\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1398\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1399\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minformation of where went wrong, or file a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1400\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missue/bug to `tf.keras`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1401\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(logs)\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;66;03m# Run validation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "for i in (range(len(data))):\n",
    "    train_note_channel(data, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92372039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415070f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c471f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing(data, n, speed, tempo, nom, denom, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "da381313",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata, n, speed, tempo, nom, denom, key = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cbe9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "96e7d769",
   "metadata": {},
   "outputs": [],
   "source": [
    "copydata = deepcopy(data)\n",
    "maintain = 6\n",
    "copydata[maintain] = rawdata[maintain]\n",
    "#postprocessing(copydata, len(copydata), speed, tempo, nom, denom, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d681581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copydata = deepcopy(data)\n",
    "#maintain = 4\n",
    "#copydata[maintain] = rawdata[maintain]\n",
    "postprocessing(copydata, len(copydata), speed, tempo, nom, denom, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950739d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0125882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessing(copydata, 5, speed, tempo, nom, denom, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a9ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d89e8b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1663 1630 33\\n30 0\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copydata[4].meta = rawdata[4].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c49a6823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2553 2516 37\\n'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copydata[5].meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acc6050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
